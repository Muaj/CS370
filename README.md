# CS370
Project Overview

This project focuses on developing a pirate intelligent agent using reinforcement learning and neural networks. The agent navigates an 8x8 maze to find treasure while avoiding obstacles, optimizing its path through Deep Q-Learning. The goal was to design and train an AI capable of pathfinding in a dynamic environment.

Code Breakdown:

Provided Code:

TreasureMaze.py: Defines the maze environment, movement rules, rewards, and penalties for the pirate agent.

GameExperience.py: Manages experience replay, storing agent experiences and training data for the neural network.

Created Code:

Q-Training Algorithm: Implemented deep Q-learning for the pirate agent. This included:

Designing the neural network using TensorFlow/Keras.

Implementing the exploration-exploitation balance (Îµ-greedy strategy).

Developing experience replay and model training logic.

Jupyter Notebook: Contains the complete pipeline for initializing the maze, training the agent, and testing its performance.

Connection to Computer Science

The Role of Computer Scientists:

Computer scientists solve complex problems by developing algorithms, designing intelligent systems, and leveraging data to drive innovation. This project mirrors real-world applications like robotics, game AI, and autonomous navigation, showcasing how reinforcement learning can adapt to dynamic environments.

Problem-Solving Approach:

As a computer scientist, problem-solving involves:

Defining the Problem: Clearly outlining the maze navigation challenge.

Algorithm Design: Selecting Q-learning for optimal pathfinding.

Implementation: Writing and debugging code to ensure efficient agent training.

Testing and Iteration: Running simulations, refining the model, and improving results based on performance feedback.

Ethical Responsibilities:

Fairness and Bias: Ensuring the AI is trained on diverse environments to generalize effectively.

Transparency: Clearly documenting the model's decisions and providing insights into its training.

User Safety: Designing the agent to perform reliably, minimizing harmful behavior in deployment.

Efficiency: Reducing unnecessary computational overhead to conserve resources.

Reflection

This project deepened my understanding of reinforcement learning, neural networks, and the broader implications of AI in computer science. I gained hands-on experience in developing intelligent systems and learned how to troubleshoot and optimize AI models. The iterative nature of training the agent reinforced the importance of persistence and adaptability in problem-solving.
